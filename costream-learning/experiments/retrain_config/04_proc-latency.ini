[wandb]
# Target value out of throughput-mean, e2e-mean, proc-mean, offset, failing
target = proc-mean

#epochs to train
epochs = 400

# epochs without training progress, otherwise early stopping
early_stopping_patience = 250

# Experimentally: Activate label normalization
label_norm = no

# Learning rate
lr = 0.002

# Tree layer class
tree_layer_name = MscnConv

# Loss function out of QLoss, MSLELoss for regression and MSELoss, BinaryCrossEntropy for classification
loss_class_name = MSLELoss

# Message passing scheme out of: full, bottom-up
message_passing_scheme = full

# Dataset to train on, out of: full, full_failing_strat, non_fail, non_fail_bp_strat,
dataset = retrain

# Optionally Previous model name to continue training. If not specified, a new model is created.
model_id = WYWAZ-retrain

# Choose activation out of LeakyReLU (recommended), CELU, SELU, ELU
activation_class_name = LeakyReLU