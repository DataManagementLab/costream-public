[wandb]
# Target value out of throughput-mean, e2e-mean, proc-mean, offset, failing
target = e2e-mean

#epochs to train
epochs = 200

# epochs without training progress, otherwise early stopping
early_stopping_patience = 20

# Experimentally: Activate label normalization
label_norm = no

# Learning rate
lr = 0.001

# Tree layer class
tree_layer_name = MscnConv

# Loss function out of QLoss, MSLELoss for regression and MSELoss, BinaryCrossEntropy for classification
loss_class_name = MSLELoss

# Message passing scheme out of: full, bottom-up
message_passing_scheme = full

# Dataset to train on, out of: full, full_failing_strat, non_fail, non_fail_bp_strat,
dataset = lower_cpu_restricted

# Optionally Previous model name to continue training. If not specified, a new model is created.
# model_id = FULL_RANGE

# Choose activation out of LeakyReLU (recommended), CELU, SELU, ELU
activation_class_name = LeakyReLU